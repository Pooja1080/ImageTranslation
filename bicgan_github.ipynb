{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from scipy.misc import imread, imresize, imsave\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['maps', 'cityscapes', 'facades', 'edges2handbags', 'edges2shoes']\n",
    "\n",
    "def read_image(path):\n",
    "    ''' Seperates input image and ground truth image from a given image path and normalizes it '''\n",
    "\n",
    "    image = imread(path)\n",
    "    h, w, c = image.shape\n",
    "    image_a = image[:, :int(w/2), :].astype(np.float32) / 255.0\n",
    "    image_b = image[:, int(w/2):, :].astype(np.float32) / 255.0\n",
    "\n",
    "    # range of pixel values = [-1.0, 1.0]\n",
    "    image_a = image_a * 2.0 - 1.0\n",
    "    image_b = image_b * 2.0 - 1.0\n",
    "    return image_a, image_b\n",
    "\n",
    "def read_images(base_dir):\n",
    "    ret = []\n",
    "    for dir_name in ['train', 'val']:\n",
    "        data_dir = os.path.join(base_dir, dir_name)\n",
    "        paths = glob(os.path.join(data_dir, '*.jpg'))\n",
    "\n",
    "        images_A = []\n",
    "        images_B = []\n",
    "        for path in tqdm(paths):\n",
    "            image_A, image_B = read_image(path)\n",
    "            if image_A is not None:\n",
    "                images_A.append(image_A)\n",
    "                images_B.append(image_B)\n",
    "        ret.append((dir_name + 'A', images_A))\n",
    "        ret.append((dir_name + 'B', images_B))\n",
    "    return ret\n",
    "    \n",
    "def store_h5py(base_dir, dir_name, images, image_size):\n",
    "    f = h5py.File(os.path.join(base_dir, '{}_{}.hy'.format(dir_name, image_size)), 'w')\n",
    "    for i in range(len(images)):\n",
    "        grp = f.create_group(str(i))\n",
    "        if images[i].shape[0] != image_size:\n",
    "            image = imresize(images[i], (image_size, image_size, 3))\n",
    "            \n",
    "            # range of pixel values = [-1.0, 1.0]\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            image = image * 2.0 - 1.0\n",
    "            grp['image'] = image\n",
    "        else:\n",
    "            grp['image'] = images[i]\n",
    "    f.close()\n",
    "\n",
    "def convert_h5py(task_name):\n",
    "    print('Generating h5py file')\n",
    "    base_dir = os.path.join('datasets', task_name)\n",
    "    data = read_images(base_dir)\n",
    "    for dir_name, images in data:\n",
    "        if images[0].shape[0] == 256:\n",
    "            store_h5py(base_dir, dir_name, images, 256)\n",
    "        store_h5py(base_dir, dir_name, images, 128)\n",
    "\n",
    "def read_h5py(task_name, image_size):\n",
    "    base_dir = 'datasets/' + task_name\n",
    "    paths = glob(os.path.join(base_dir, '*_{}.hy'.format(image_size)))\n",
    "    if len(paths) != 4:\n",
    "        convert_h5py(task_name)\n",
    "    ret = []\n",
    "    for dir_name in ['trainA', 'trainB', 'valA', 'valB']:\n",
    "        try:\n",
    "            dataset = h5py.File(os.path.join(base_dir, '{}_{}.hy'.format(dir_name, image_size)), 'r')\n",
    "        except:\n",
    "            raise IOError('Dataset is not available. Please try it again')\n",
    "\n",
    "        images = []\n",
    "        for id in dataset:\n",
    "            images.append(dataset[id]['image'].value.astype(np.float32))\n",
    "        ret.append(images)\n",
    "    return ret\n",
    "\n",
    "def get_data(task_name, image_size):\n",
    "    base_dir = os.path.join('datasets', task_name)\n",
    "\n",
    "    print('Load data %s' % task_name)\n",
    "    train_A, train_B, test_A, test_B = \\\n",
    "        read_h5py(task_name, image_size)\n",
    "    return train_A, train_B, test_A, test_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(object):\n",
    "    def __init__(self, name, is_train, norm='instance', activation='leaky', image_size=128):\n",
    "        logger.info('Init Discriminator %s', name)\n",
    "        self.name = name\n",
    "        self._is_train = is_train\n",
    "        self._norm = norm\n",
    "        self._activation = activation\n",
    "        self._reuse = False\n",
    "        self._image_size = image_size\n",
    "\n",
    "    def __call__(self, input):\n",
    "        with tf.variable_scope(self.name, reuse=self._reuse):\n",
    "            D = conv_block(input, 64, 'C64', 4, 2, self._is_train,\n",
    "                               self._reuse, norm=None, activation=self._activation)\n",
    "            D = conv_block(D, 128, 'C128', 4, 2, self._is_train,\n",
    "                               self._reuse, self._norm, self._activation)\n",
    "            D = conv_block(D, 256, 'C256', 4, 2, self._is_train,\n",
    "                               self._reuse, self._norm, self._activation)\n",
    "            num_layers = 3 if self._image_size == 256 else 1\n",
    "            for i in range(num_layers):\n",
    "                D = conv_block(D, 512, 'C512_{}'.format(i), 4, 2, self._is_train,\n",
    "                                   self._reuse, self._norm, self._activation)\n",
    "            D = conv_block(D, 1, 'C1', 4, 1, self._is_train,\n",
    "                               self._reuse, norm=None, activation=None, bias=True)\n",
    "            D = tf.reduce_mean(D, axis=[1,2,3])\n",
    "\n",
    "            self._reuse = True\n",
    "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
    "            return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "    def __init__(self, name, is_train, norm='instance', activation='leaky',\n",
    "                 image_size=128, latent_dim=8, use_resnet=True):\n",
    "        logger.info('Init Encoder %s', name)\n",
    "        self.name = name\n",
    "        self._is_train = is_train\n",
    "        self._norm = norm\n",
    "        self._activation = activation\n",
    "        self._reuse = False\n",
    "        self._image_size = image_size\n",
    "        self._latent_dim = latent_dim\n",
    "        self._use_resnet = use_resnet\n",
    "\n",
    "    def __call__(self, input):\n",
    "        if self._use_resnet:\n",
    "            return self._resnet(input)\n",
    "        else:\n",
    "            return self._convnet(input)\n",
    "\n",
    "    def _convnet(self, input):\n",
    "        with tf.variable_scope(self.name, reuse=self._reuse):\n",
    "            num_filters = [64, 128, 256, 512, 512, 512, 512]\n",
    "            if self._image_size == 256:\n",
    "                num_filters.append(512)\n",
    "\n",
    "            E = input\n",
    "            for i, n in enumerate(num_filters):\n",
    "                E = conv_block(E, n, 'C{}_{}'.format(n, i), 4, 2, self._is_train,\n",
    "                                   self._reuse, norm=self._norm if i else None, activation='leaky')\n",
    "            E = flatten(E)\n",
    "            mu = mlp(E, self._latent_dim, 'FC8_mu', self._is_train, self._reuse,\n",
    "                         norm=None, activation=None)\n",
    "            log_sigma = mlp(E, self._latent_dim, 'FC8_sigma', self._is_train, self._reuse,\n",
    "                                norm=None, activation=None)\n",
    "\n",
    "            z = mu + tf.random_normal(shape=tf.shape(self._latent_dim)) * tf.exp(log_sigma)\n",
    "\n",
    "            self._reuse = True\n",
    "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
    "            return z, mu, log_sigma\n",
    "\n",
    "    def _resnet(self, input):\n",
    "        with tf.variable_scope(self.name, reuse=self._reuse):\n",
    "            num_filters = [128, 256, 512, 512]\n",
    "            if self._image_size == 256:\n",
    "                num_filters.append(512)\n",
    "\n",
    "            E = input\n",
    "            E = conv_block(E, 64, 'C{}_{}'.format(64, 0), 4, 2, self._is_train,\n",
    "                               self._reuse, norm=None, activation='leaky', bias=True)\n",
    "            for i, n in enumerate(num_filters):\n",
    "                E = residual(E, n, 'res{}_{}'.format(n, i + 1), self._is_train,\n",
    "                                 self._reuse, norm=self._norm, bias=True)\n",
    "                E = tf.nn.avg_pool(E, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "            E = tf.nn.relu(E)\n",
    "            E = tf.nn.avg_pool(E, [1, 8, 8, 1], [1, 8, 8, 1], 'SAME')\n",
    "            E = flatten(E)\n",
    "            mu = mlp(E, self._latent_dim, 'FC8_mu', self._is_train, self._reuse,\n",
    "                         norm=None, activation=None)\n",
    "            log_sigma = mlp(E, self._latent_dim, 'FC8_sigma', self._is_train, self._reuse,\n",
    "                                norm=None, activation=None)\n",
    "\n",
    "            z = mu + tf.random_normal(shape=tf.shape(self._latent_dim)) * tf.exp(log_sigma)\n",
    "\n",
    "            self._reuse = True\n",
    "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
    "            return z, mu, log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, name, is_train, norm='batch', image_size=128):\n",
    "        logger.info('Init Generator %s', name)\n",
    "        self.name = name\n",
    "        self._is_train = is_train\n",
    "        self._norm = norm\n",
    "        self._reuse = False\n",
    "        self._image_size = image_size\n",
    "\n",
    "    def __call__(self, input, z):\n",
    "        with tf.variable_scope(self.name, reuse=self._reuse):\n",
    "            batch_size = int(input.get_shape()[0])\n",
    "            latent_dim = int(z.get_shape()[-1])\n",
    "            num_filters = [64, 128, 256, 512, 512, 512, 512]\n",
    "            if self._image_size == 256:\n",
    "                num_filters.append(512)\n",
    "\n",
    "            layers = []\n",
    "            G = input\n",
    "            z = tf.reshape(z, [batch_size, 1, 1, latent_dim])\n",
    "            z = tf.tile(z, [1, self._image_size, self._image_size, 1])\n",
    "            G = tf.concat([G, z], axis=3)\n",
    "            for i, n in enumerate(num_filters):\n",
    "                G = conv_block(G, n, 'C{}_{}'.format(n, i), 4, 2, self._is_train,\n",
    "                                self._reuse, norm=self._norm if i else None, activation='leaky')\n",
    "                layers.append(G)\n",
    "\n",
    "            layers.pop()\n",
    "            num_filters.pop()\n",
    "            num_filters.reverse()\n",
    "\n",
    "            for i, n in enumerate(num_filters):\n",
    "                G = deconv_block(G, n, 'CD{}_{}'.format(n, i), 4, 2, self._is_train,\n",
    "                                self._reuse, norm=self._norm, activation='relu')\n",
    "                G = tf.concat([G, layers.pop()], axis=3)\n",
    "            G = deconv_block(G, 3, 'last_layer', 4, 2, self._is_train,\n",
    "                               self._reuse, norm=None, activation='tanh')\n",
    "\n",
    "            self._reuse = True\n",
    "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
    "            return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm(input, is_train, reuse=True, norm=None):\n",
    "    assert norm in ['instance', 'batch', None]\n",
    "    if norm == 'instance':\n",
    "        with tf.variable_scope('instance_norm', reuse=reuse):\n",
    "            eps = 1e-5\n",
    "            mean, sigma = tf.nn.moments(input, [1, 2], keep_dims=True)\n",
    "            normalized = (input - mean) / (tf.sqrt(sigma) + eps)\n",
    "            out = normalized\n",
    "\n",
    "    elif norm == 'batch':\n",
    "        with tf.variable_scope('batch_norm', reuse=reuse):\n",
    "            out = tf.contrib.layers.batch_norm(input,\n",
    "                                               decay=0.99, center=True,\n",
    "                                               scale=True, is_training=True)\n",
    "    else:\n",
    "        out = input\n",
    "\n",
    "    return out\n",
    "\n",
    "def _activation(input, activation=None):\n",
    "    assert activation in ['relu', 'leaky', 'tanh', 'sigmoid', None]\n",
    "    if activation == 'relu':\n",
    "        return tf.nn.relu(input)\n",
    "    elif activation == 'leaky':\n",
    "        return tf.contrib.keras.layers.LeakyReLU(0.2)(input)\n",
    "    elif activation == 'tanh':\n",
    "        return tf.tanh(input)\n",
    "    elif activation == 'sigmoid':\n",
    "        return tf.sigmoid(input)\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "def flatten(input):\n",
    "    return tf.reshape(input, [-1, np.prod(input.get_shape().as_list()[1:])])\n",
    "\n",
    "def conv2d(input, num_filters, filter_size, stride, reuse=False,\n",
    "           pad='SAME', dtype=tf.float32, bias=False):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [filter_size, filter_size, input.get_shape()[3], num_filters]\n",
    "\n",
    "    w = tf.get_variable('w', filter_shape, dtype, tf.random_normal_initializer(0.0, 0.02))\n",
    "    if pad == 'REFLECT':\n",
    "        p = (filter_size - 1) // 2\n",
    "        x = tf.pad(input, [[0,0],[p,p],[p,p],[0,0]], 'REFLECT')\n",
    "        conv = tf.nn.conv2d(x, w, stride_shape, padding='VALID')\n",
    "    else:\n",
    "        assert pad in ['SAME', 'VALID']\n",
    "        conv = tf.nn.conv2d(input, w, stride_shape, padding=pad)\n",
    "\n",
    "    if bias:\n",
    "        b = tf.get_variable('b', [1,1,1,num_filters], initializer=tf.constant_initializer(0.0))\n",
    "        conv = conv + b\n",
    "    return conv\n",
    "\n",
    "def conv2d_transpose(input, num_filters, filter_size, stride, reuse,\n",
    "                     pad='SAME', dtype=tf.float32):\n",
    "    assert pad == 'SAME'\n",
    "    n, h, w, c = input.get_shape().as_list()\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [filter_size, filter_size, num_filters, c]\n",
    "    output_shape = [n, h * stride, w * stride, num_filters]\n",
    "\n",
    "    w = tf.get_variable('w', filter_shape, dtype, tf.random_normal_initializer(0.0, 0.02))\n",
    "    deconv = tf.nn.conv2d_transpose(input, w, output_shape, stride_shape, pad)\n",
    "    return deconv\n",
    "\n",
    "def mlp(input, out_dim, name, is_train, reuse, norm=None, activation=None,\n",
    "        dtype=tf.float32, bias=True):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        _, n = input.get_shape()\n",
    "        w = tf.get_variable('w', [n, out_dim], dtype, tf.random_normal_initializer(0.0, 0.02))\n",
    "        out = tf.matmul(input, w)\n",
    "        if bias:\n",
    "            b = tf.get_variable('b', [out_dim], initializer=tf.constant_initializer(0.0))\n",
    "            out = out + b\n",
    "        out = _activation(out, activation)\n",
    "        out = _norm(out, is_train, reuse, norm)\n",
    "        return out\n",
    "\n",
    "def conv_block(input, num_filters, name, k_size, stride, is_train, reuse, norm,\n",
    "          activation, pad='SAME', bias=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        out = conv2d(input, num_filters, k_size, stride, reuse, pad, bias=bias)\n",
    "        out = _norm(out, is_train, reuse, norm)\n",
    "        out = _activation(out, activation)\n",
    "        return out\n",
    "\n",
    "def residual(input, num_filters, name, is_train, reuse, norm, pad='REFLECT',\n",
    "             bias=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        with tf.variable_scope('res1', reuse=reuse):\n",
    "            out = conv2d(input, num_filters, 3, 1, reuse, pad, bias=bias)\n",
    "            out = _norm(out, is_train, reuse, norm)\n",
    "            out = tf.nn.relu(out)\n",
    "\n",
    "        with tf.variable_scope('res2', reuse=reuse):\n",
    "            out = conv2d(out, num_filters, 3, 1, reuse, pad, bias=bias)\n",
    "            out = _norm(out, is_train, reuse, norm)\n",
    "\n",
    "        with tf.variable_scope('shortcut', reuse=reuse):\n",
    "            shortcut = conv2d(input, num_filters, 1, 1, reuse, pad, bias=bias)\n",
    "\n",
    "        return tf.nn.relu(shortcut + out)\n",
    "\n",
    "def deconv_block(input, num_filters, name, k_size, stride, is_train, reuse,\n",
    "                 norm, activation):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        out = conv2d_transpose(input, num_filters, k_size, stride, reuse)\n",
    "        out = _norm(out, is_train, reuse, norm)\n",
    "        out = _activation(out, activation)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Start BicycleGAN\")\n",
    "logger = logging.getLogger('Bicycle-gan')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def makedirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "args = defaultdict(dict)\n",
    "args['train'] = True\n",
    "args['task'] = 'facades'\n",
    "args['coeff_gan'] = 1.0\n",
    "args['coeff_vae'] = 1.0\n",
    "args['coeff_kl'] = 0.01\n",
    "args['coeff_reconstruct'] = 10\n",
    "args['coeff_latent'] = 0.5\n",
    "args['instance_normalization'] = False\n",
    "args['log_step'] = 100\n",
    "args['batch_size'] = 1\n",
    "args['image_size'] = 256\n",
    "args['latent_dim'] = 8\n",
    "args['use_resnet'] = True\n",
    "args['load_model'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BicycleGAN(object):\n",
    "    def __init__(self, args):\n",
    "        self._log_step = args['log_step']\n",
    "        self._batch_size = args['batch_size']\n",
    "        self._image_size = args['image_size']\n",
    "        self._latent_dim = args['latent_dim']\n",
    "        self._coeff_gan = args['coeff_gan']\n",
    "        self._coeff_vae = args['coeff_vae']\n",
    "        self._coeff_reconstruct = args['coeff_reconstruct']\n",
    "        self._coeff_latent = args['coeff_latent']\n",
    "        self._coeff_kl = args['coeff_kl']\n",
    "        self._norm = 'instance' if args['instance_normalization'] else 'batch'\n",
    "        self._use_resnet = args['use_resnet']\n",
    "\n",
    "        self._augment_size = self._image_size + (30 if self._image_size == 256 else 15)\n",
    "        self._image_shape = [self._image_size, self._image_size, 3]\n",
    "\n",
    "        self.is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "        self.lr = tf.placeholder(tf.float32, name='lr')\n",
    "        self.global_step = tf.train.get_or_create_global_step(graph=None)\n",
    "\n",
    "        image_a = self.image_a = \\\n",
    "            tf.placeholder(tf.float32, [self._batch_size] + self._image_shape, name='image_a')\n",
    "        image_b = self.image_b = \\\n",
    "            tf.placeholder(tf.float32, [self._batch_size] + self._image_shape, name='image_b')\n",
    "        z = self.z = \\\n",
    "            tf.placeholder(tf.float32, [self._batch_size, self._latent_dim], name='z')\n",
    "\n",
    "        # Data augmentation\n",
    "        seed = random.randint(0, 2**31 - 1)\n",
    "        def augment_image(image):\n",
    "            image = tf.image.resize_images(image, [self._augment_size, self._augment_size])\n",
    "            image = tf.random_crop(image, [self._batch_size] + self._image_shape, seed=seed)\n",
    "            image = tf.map_fn(lambda x: tf.image.random_flip_left_right(x, seed), image)\n",
    "            return image\n",
    "\n",
    "        image_a = tf.cond(self.is_train,\n",
    "                          lambda: augment_image(image_a),\n",
    "                          lambda: image_a)\n",
    "        image_b = tf.cond(self.is_train,\n",
    "                          lambda: augment_image(image_b),\n",
    "                          lambda: image_b)\n",
    "\n",
    "        # Generator\n",
    "        G = Generator('G', is_train=self.is_train,\n",
    "                      norm=self._norm, image_size=self._image_size)\n",
    "\n",
    "        # Discriminator\n",
    "        D = Discriminator('D', is_train=self.is_train,\n",
    "                          norm=self._norm, activation='leaky',\n",
    "                          image_size=self._image_size)\n",
    "\n",
    "        # Encoder\n",
    "        E = Encoder('E', is_train=self.is_train,\n",
    "                    norm=self._norm, activation='relu',\n",
    "                    image_size=self._image_size, latent_dim=self._latent_dim,\n",
    "                    use_resnet=self._use_resnet)\n",
    "\n",
    "        # conditional VAE-GAN: B -> z -> B'\n",
    "        z_encoded, z_encoded_mu, z_encoded_log_sigma = E(image_b)\n",
    "        image_ab_encoded = G(image_a, z_encoded)\n",
    "\n",
    "        # conditional Latent Regressor-GAN: z -> B' -> z'\n",
    "        image_ab = self.image_ab = G(image_a, z)\n",
    "        z_recon, z_recon_mu, z_recon_log_sigma = E(image_ab)\n",
    "\n",
    "\n",
    "        # Discriminate real/fake images\n",
    "        D_real = D(image_b)\n",
    "        D_fake = D(image_ab)\n",
    "        D_fake_encoded = D(image_ab_encoded)\n",
    "\n",
    "        loss_vae_gan = (tf.reduce_mean(tf.squared_difference(D_real, 0.9)) +\n",
    "            tf.reduce_mean(tf.square(D_fake_encoded)))\n",
    "\n",
    "        loss_image_cycle = tf.reduce_mean(tf.abs(image_b - image_ab_encoded))\n",
    "\n",
    "        loss_gan = (tf.reduce_mean(tf.squared_difference(D_real, 0.9)) +\n",
    "            tf.reduce_mean(tf.square(D_fake)))\n",
    "\n",
    "        loss_latent_cycle = tf.reduce_mean(tf.abs(z - z_recon))\n",
    "\n",
    "        loss_kl = -0.5 * tf.reduce_mean(1 + 2 * z_encoded_log_sigma - z_encoded_mu ** 2 -\n",
    "                                       tf.exp(2 * z_encoded_log_sigma))\n",
    "\n",
    "        loss = self._coeff_vae * loss_vae_gan - self._coeff_reconstruct * loss_image_cycle + \\\n",
    "            self._coeff_gan * loss_gan - self._coeff_latent * loss_latent_cycle - \\\n",
    "            self._coeff_kl * loss_kl\n",
    "\n",
    "        # Optimizer\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.optimizer_D = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5) \\\n",
    "                                .minimize(loss, var_list=D.var_list, global_step=self.global_step)\n",
    "            self.optimizer_G = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5) \\\n",
    "                                .minimize(-loss, var_list=G.var_list)\n",
    "            self.optimizer_E = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5) \\\n",
    "                                .minimize(-loss, var_list=E.var_list)\n",
    "\n",
    "        # Summaries\n",
    "        self.loss_vae_gan = loss_vae_gan\n",
    "        self.loss_image_cycle = loss_image_cycle\n",
    "        self.loss_latent_cycle = loss_latent_cycle\n",
    "        self.loss_gan = loss_gan\n",
    "        self.loss_kl = loss_kl\n",
    "        self.loss = loss\n",
    "\n",
    "        tf.summary.scalar('loss/vae_gan', loss_vae_gan)\n",
    "        tf.summary.scalar('loss/image_cycle', loss_image_cycle)\n",
    "        tf.summary.scalar('loss/latent_cycle', loss_latent_cycle)\n",
    "        tf.summary.scalar('loss/gan', loss_gan)\n",
    "        tf.summary.scalar('loss/kl', loss_kl)\n",
    "        tf.summary.scalar('loss/total', loss)\n",
    "        tf.summary.scalar('model/D_real', tf.reduce_mean(D_real))\n",
    "        tf.summary.scalar('model/D_fake', tf.reduce_mean(D_fake))\n",
    "        tf.summary.scalar('model/D_fake_encoded', tf.reduce_mean(D_fake_encoded))\n",
    "        tf.summary.scalar('model/lr', self.lr)\n",
    "        tf.summary.image('image/A', image_a[0:1])\n",
    "        tf.summary.image('image/B', image_b[0:1])\n",
    "        tf.summary.image('image/A-B', image_ab[0:1])\n",
    "        tf.summary.image('image/A-B_encoded', image_ab_encoded[0:1])\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "                \n",
    "    def train(self, sess, summary_writer, data_A, data_B):\n",
    "        logger.info('Start training.')\n",
    "        logger.info('  {} images from A'.format(len(data_A)))\n",
    "        logger.info('  {} images from B'.format(len(data_B)))\n",
    "\n",
    "        assert len(data_A) == len(data_B), \\\n",
    "            'Data size mismatch dataA(%d) dataB(%d)' % (len(data_A), len(data_B))\n",
    "        data_size = len(data_A)\n",
    "        num_batch = data_size // self._batch_size\n",
    "        epoch_length = 310\n",
    "        \n",
    "        num_initial_iter = 8\n",
    "        num_decay_iter = 2\n",
    "        lr = lr_initial = 0.0002\n",
    "        lr_decay = lr_initial / num_decay_iter\n",
    "  \n",
    "        initial_step = sess.run(self.global_step)\n",
    "        num_global_step = (num_initial_iter + num_decay_iter) * epoch_length\n",
    "        t = trange(initial_step, num_global_step,\n",
    "                   total=num_global_step, initial=initial_step)\n",
    "\n",
    "        for step in t:\n",
    "            epoch = step // epoch_length\n",
    "            iter = step % epoch_length\n",
    "\n",
    "            if epoch > num_initial_iter:\n",
    "                lr = max(0.0, lr_initial - (epoch - num_initial_iter) * lr_decay)\n",
    "\n",
    "            if iter == 0:\n",
    "                data = list(zip(data_A, data_B))\n",
    "                random.shuffle(data)\n",
    "                data_A, data_B = zip(*data)\n",
    "\n",
    "            image_a = np.stack(data_A[iter*self._batch_size:(iter+1)*self._batch_size])\n",
    "            image_b = np.stack(data_B[iter*self._batch_size:(iter+1)*self._batch_size])\n",
    "            sample_z = np.random.normal(size=(self._batch_size, self._latent_dim))\n",
    "\n",
    "            fetches = [self.loss, self.optimizer_D,\n",
    "                       self.optimizer_G, self.optimizer_E]\n",
    "            if step % self._log_step == 0:\n",
    "                fetches += [self.summary_op]\n",
    "\n",
    "            fetched = sess.run(fetches, feed_dict={self.image_a: image_a,\n",
    "                                                   self.image_b: image_b,\n",
    "                                                   self.is_train: True,\n",
    "                                                   self.lr: lr,\n",
    "                                                   self.z: sample_z})\n",
    "\n",
    "            if step % self._log_step == 0:\n",
    "                z = np.random.normal(size=(1, self._latent_dim))\n",
    "                image_ab = sess.run(self.image_ab, feed_dict={self.image_a: image_a,\n",
    "                                                            self.z: z,\n",
    "                                                            self.is_train: False})\n",
    "                imsave('results/r_{}.jpg'.format(step), np.squeeze(image_ab, axis=0))\n",
    "\n",
    "                summary_writer.add_summary(fetched[-1], step)\n",
    "                summary_writer.flush()\n",
    "                t.set_description('Loss({:.3f})'.format(fetched[0]))\n",
    "\n",
    "    def test(self, sess, data_A, data_B, base_dir):\n",
    "        step = 0\n",
    "        for (dataA, dataB) in tqdm(zip(data_A, data_B)):\n",
    "            step += 1\n",
    "            image_a = np.expand_dims(dataA, axis=0)\n",
    "            image_b = np.expand_dims(dataB, axis=0)\n",
    "            images_random = []\n",
    "            images_random.append(image_a)\n",
    "            images_random.append(image_b)\n",
    "            images_linear = []\n",
    "            images_linear.append(image_a)\n",
    "            images_linear.append(image_b)\n",
    "\n",
    "            z = np.random.normal(size=(1, self._latent_dim))\n",
    "            image_ab = sess.run(self.image_ab, feed_dict={self.image_a: image_a,\n",
    "                                                         self.z: z,\n",
    "                                                         self.is_train: False})\n",
    "            images_random.append(image_ab)\n",
    "            \n",
    "            z = np.zeros((1, self._latent_dim))\n",
    "            image_ab = sess.run(self.image_ab, feed_dict={self.image_a: image_a,\n",
    "                                                         self.z: z,\n",
    "                                                         self.is_train: False})\n",
    "            images_linear.append(image_ab)\n",
    "            \n",
    "            images = np.concatenate(images_random, axis=1)\n",
    "            images = np.squeeze(images, axis=0)        \n",
    "            imsave(os.path.join(base_dir, 'random_{}.jpg'.format(step)), images)\n",
    "            \n",
    "            images = np.concatenate(images_linear, axis=1)\n",
    "            images = np.squeeze(images, axis=0)\n",
    "            imsave(os.path.join(base_dir, 'linear_{}.jpg'.format(step)), images)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() == 'true'\n",
    "\n",
    "class FastSaver(tf.train.Saver):\n",
    "    def save(self, sess, save_path, global_step=None, latest_filename=None,\n",
    "             meta_graph_suffix=\"meta\", write_meta_graph=True):\n",
    "        super(FastSaver, self).save(sess, save_path, global_step, latest_filename,\n",
    "                                    meta_graph_suffix, False)\n",
    "\n",
    "\n",
    "def run(args):\n",
    "    logger.info('Read data:')\n",
    "    train_A, train_B, test_A, test_B = get_data(args['task'], args['image_size'])\n",
    "\t\n",
    "    tempA = train_A\n",
    "    train_A = train_B\n",
    "    train_B = tempA\n",
    "\t\n",
    "    tempB = test_A\n",
    "    test_A = test_B\n",
    "    test_B = tempB\n",
    "\t\n",
    "    logger.info('Build graph:')\n",
    "    model = BicycleGAN(args)\n",
    "\n",
    "    variables_to_save = tf.global_variables()\n",
    "    init_op = tf.variables_initializer(variables_to_save)\n",
    "    init_all_op = tf.global_variables_initializer()\n",
    "    saver = FastSaver(variables_to_save)\n",
    "\n",
    "    logger.info('Trainable vars:')\n",
    "    var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                 tf.get_variable_scope().name)\n",
    "    for v in var_list:\n",
    "        logger.info('  %s %s', v.name, v.get_shape())\n",
    "\n",
    "    if args['load_model'] != '':\n",
    "        model_name = args['load_model']\n",
    "    else:\n",
    "        model_name = '{}_{}'.format(args['task'], datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    logdir = './logs'\n",
    "    makedirs(logdir)\n",
    "    logdir = os.path.join(logdir, model_name)\n",
    "    logger.info('Events directory: %s', logdir)\n",
    "    summary_writer = tf.summary.FileWriter(logdir)\n",
    "\n",
    "    makedirs('./results')\n",
    "\n",
    "    def init_fn(sess):\n",
    "        logger.info('Initializing all parameters.')\n",
    "        sess.run(init_all_op)\n",
    "\n",
    "    sv = tf.train.Supervisor(is_chief=True,\n",
    "                             logdir=logdir,\n",
    "                             saver=saver,\n",
    "                             summary_op=None,\n",
    "                             init_op=init_op,\n",
    "                             init_fn=init_fn,\n",
    "                             summary_writer=summary_writer,\n",
    "                             ready_op=tf.report_uninitialized_variables(variables_to_save),\n",
    "                             global_step=model.global_step,\n",
    "                             save_model_secs=300,\n",
    "                             save_summaries_secs=30)\n",
    "\n",
    "    if args['train']:\n",
    "        logger.info(\"Starting training session.\")\n",
    "        with sv.managed_session() as sess:\n",
    "            model.train(sess, summary_writer, train_A, train_B)\n",
    "\n",
    "    logger.info(\"Starting testing session.\")\n",
    "    with sv.managed_session() as sess:\n",
    "        base_dir = os.path.join('results', model_name)\n",
    "        makedirs(base_dir)\n",
    "        model.test(sess, test_A, test_B, base_dir)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    def shutdown(signal, frame):\n",
    "        tf.logging.warn('Received signal %s: exiting', signal)\n",
    "        sys.exit(128+signal)\n",
    "    signal.signal(signal.SIGINT, shutdown)\n",
    "    signal.signal(signal.SIGTERM, shutdown)\n",
    "\n",
    "    run(args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
